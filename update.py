def extract_date_from_text(text: str) -> str | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å—Ç–∞"""
    t = text.lower()

    # 1) dd.mm.yyyy / dd-mm-yyyy / dd/mm/yyyy
    m = re.search(r'(\d{1,2})[.\-/](\d{1,2})[.\-/](\d{4})', t)
    if m:
        d, mo, y = int(m.group(1)), int(m.group(2)), int(m.group(3))
        try:
            return date(y, mo, d).isoformat()
        except Exception:
            pass

    # 2) dd.mm (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π)
    m = re.search(r'(\d{1,2})[.\-/](\d{1,2})(?!\d)', t)
    if m:
        d, mo = int(m.group(1)), int(m.group(2))
        if 1 <= d <= 31 and 1 <= mo <= 12:
            y = date.today().year
            try:
                return date(y, mo, d).isoformat()
            except Exception:
                pass

    # 3) "24 —Å—ñ—á–Ω—è 2026" / "24 —è–Ω–≤–∞—Ä—è 2026"
    m = re.search(r'\b(\d{1,2})\s+([–∞-—è—ñ—ó—î]+)\s+(\d{4})\b', t)
    if m:
        d = int(m.group(1))
        mon_name = m.group(2)
        y = int(m.group(3))
        mo = MONTHS_UA_RU.get(mon_name)
        if mo and 1 <= d <= 31:
            try:
                return date(y, mo, d).isoformat()
            except Exception:
                pass

    # 4) "24 —Å—ñ—á–Ω—è" (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π) - –∏—Å–ø–æ–ª—å–∑—É–µ–º \b –¥–ª—è –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞
    m = re.search(r'\b(\d{1,2}import os
import re
import json
import html
import subprocess
import time
from datetime import datetime, date, timezone, timedelta
from random import randint
import requests

# ====== –ù–ê–°–¢–†–û–ô–ö–ò ======
CHANNEL = os.getenv("TG_CHANNEL", "dnepr_svet_voda").strip()
TG_URL = f"https://t.me/s/{CHANNEL}"
SCHEDULE_PATH = os.getenv("SCHEDULE_PATH", "schedule.json")
TIMEZONE_NAME = os.getenv("TIMEZONE", "Europe/Kyiv")

KEYWORDS = [k.strip().lower() for k in os.getenv(
    "TG_KEYWORDS",
    "–æ–Ω–æ–≤,–æ–Ω–æ–≤–∏–≤,–æ–Ω–æ–≤–∏–ª–∏—Å—å,–≥—Ä–∞—Ñ–∏–∫,–≥—Ä–∞—Ñ—ñ–∫–∏,–≥—Ä–∞—Ñ—ñ–∫,–¥—Ç–µ–∫,yasno,–≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è,–≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è —Å–≤—ñ—Ç–ª–∞,—á–µ—Ä–≥–∞,–≥—Ä—É–ø–∞"
).split(",") if k.strip()]

LOOKBACK = int(os.getenv("TG_LOOKBACK", "200"))

UPDATE_IF_DATE_CHANGED = os.getenv("UPDATE_IF_DATE_CHANGED", "0") == "1"

GITHUB_REPO = os.getenv("GITHUB_REPO", "")
GITHUB_PAT = os.getenv("GITHUB_PAT", "")
GIT_NAME = os.getenv("GIT_NAME", "Auto Updater")
GIT_EMAIL = os.getenv("GIT_EMAIL", "auto@local")


# ====== git helpers ======
def run(cmd: list[str]):
    subprocess.check_call(cmd)

def git_push_if_changed():
    try:
        status = subprocess.check_output(["git", "status", "--porcelain"], text=True).strip()
        if not status:
            print("No changes to commit.")
            return

        run(["git", "config", "user.name", GIT_NAME])
        run(["git", "config", "user.email", GIT_EMAIL])
        run(["git", "add", SCHEDULE_PATH])
        run(["git", "commit", "-m", f"update schedule {date.today()}"])

        try:
            run(["git", "pull", "--rebase"])
        except subprocess.CalledProcessError:
            print("Warning: git pull failed, trying to push anyway...")

        if GITHUB_REPO and GITHUB_PAT:
            repo_with_pat = re.sub(r"^https://", f"https://{GITHUB_PAT}@", GITHUB_REPO)
            run(["git", "push", repo_with_pat, "HEAD:main"])
        else:
            run(["git", "push"])
        
        print("‚úÖ Successfully pushed changes to repository")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Git operation failed: {e}")
        raise


# ====== schedule helpers ======
def load_existing():
    if not os.path.exists(SCHEDULE_PATH):
        return {}
    with open(SCHEDULE_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

def save_schedule(groups: dict, date_str: str):
    data = {"date": date_str, "timezone": TIMEZONE_NAME, "groups": groups}
    with open(SCHEDULE_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ====== –£–ª—É—á—à–µ–Ω–Ω—ã–π fetch —Å –æ–±—Ö–æ–¥–æ–º –∫—ç—à–∞ ======
def fetch_with_retry(url: str, retries: int = 3):
    """–ü—ã—Ç–∞–µ–º—Å—è –æ–±–æ–π—Ç–∏ –∫—ç—à —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ User-Agent –∏ timestamp"""
    
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    ]
    
    for i in range(retries):
        try:
            cache_buster = f"?_={int(time.time() * 1000)}"
            headers = {
                'User-Agent': user_agents[i % len(user_agents)],
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'uk-UA,uk;q=0.9,en-US;q=0.8,en;q=0.7'
            }
            
            print(f"Fetching {url} (attempt {i+1}/{retries})...")
            r = requests.get(url + cache_buster, headers=headers, timeout=20)
            r.raise_for_status()
            print(f"Successfully fetched page ({len(r.text)} bytes)")
            return r.text
        except Exception as e:
            print(f"Attempt {i+1} failed: {e}")
            if i == retries - 1:
                raise
            time.sleep(randint(2, 5))


# ====== Telegram HTML parsing ======
def extract_messages(page_html: str):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Telegram"""
    msgs = []
    
    # –ò—â–µ–º –±–ª–æ–∫–∏ —Å data-post
    post_blocks = re.finditer(
        r'data-post="([^"]+)".*?<div[^>]*class="[^"]*tgme_widget_message_text[^"]*"[^>]*>(.*?)</div>',
        page_html,
        re.S
    )
    
    for match in post_blocks:
        post_id = match.group(1)
        text_html = match.group(2)
        
        # –ò—â–µ–º timestamp –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç—è—Ö (–∏—â–µ–º –≤ 1000 —Å–∏–º–≤–æ–ª–∞—Ö –¥–æ match)
        start_pos = max(0, match.start() - 1000)
        context = page_html[start_pos:match.end()]
        
        m_ts = re.search(r'data-unixtime="(\d+)"', context)
        ts = int(m_ts.group(1)) if m_ts else 0
        
        # –û—á–∏—Å—Ç–∫–∞ HTML
        text_html = text_html.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")
        text_plain = re.sub(r"<.*?>", "", text_html)
        text_plain = html.unescape(text_plain).strip()
        
        if text_plain:
            msgs.append({"ts": ts, "post": post_id, "text": text_plain})
    
    msgs.sort(key=lambda x: x["ts"])
    return msgs


def has_group_lines(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å—Ç—Ä–æ–∫ —Å –≥—Ä—É–ø–ø–∞–º–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–π"""
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: "1.1 03:00" –∏–ª–∏ "1.1 - 08:00"
    return bool(re.search(r'(^|\n)\s*\d+\.\d+\s+\d{2}:\d{2}', text, re.MULTILINE))


def has_keywords(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
    low = text.lower()
    return any(k in low for k in KEYWORDS)


def parse_groups(text: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
    - 1.1 03:00 - 10:00 / 13:30 - 20:30
    - 1.1 - 08:00-12:00, 16:00-20:00
    - 1.1: 08:00-12:00; 16:00-20:00
    """
    groups = {}
    norm = text.replace("‚Äì", "-").replace("‚Äî", "-").replace("‚àí", "-")

    for line in norm.splitlines():
        line = line.strip()
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏ –º–∞—Ä–∫–µ—Ä—ã
        line = re.sub(r'^[‚Ä¢üî¥‚ùå\-\s]+', '', line)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω: "1.1 03:00 - 10:00 / 13:30 - 20:30"
        m = re.match(r'^(\d+\.\d+)\s+(.+)$', line)
        if not m:
            continue

        group_id = m.group(1)
        rest = m.group(2).strip()
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø–æ / –∏–ª–∏ ;
        parts = [p.strip() for p in re.split(r'[/;]', rest) if p.strip()]
        
        intervals = []
        for part in parts:
            # –ò—â–µ–º –≤—Å–µ –≤—Ä–µ–º–µ–Ω–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM
            times = re.findall(r'\d{2}:\d{2}', part)
            
            # –°–æ–∑–¥–∞—ë–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –∏–∑ –ø–∞—Ä –≤—Ä–µ–º—ë–Ω
            for i in range(0, len(times) - 1, 2):
                interval = f"{times[i]}-{times[i+1]}"
                intervals.append(interval)

        if intervals:
            groups[group_id] = intervals

    if not groups:
        raise RuntimeError("Parsed 0 groups from candidate post (format changed?)")
    
    return groups


# ====== Extract date from post text ======
MONTHS_UA_RU = {
    "—Å—ñ—á–Ω—è": 1, "—è–Ω–≤–∞—Ä—è": 1,
    "–ª—é—Ç–æ–≥–æ": 2, "—Ñ–µ–≤—Ä–∞–ª—è": 2,
    "–±–µ—Ä–µ–∑–Ω—è": 3, "–º–∞—Ä—Ç–∞": 3,
    "–∫–≤—ñ—Ç–Ω—è": 4, "–∞–ø—Ä–µ–ª—è": 4,
    "—Ç—Ä–∞–≤–Ω—è": 5, "–º–∞—è": 5,
    "—á–µ—Ä–≤–Ω—è": 6, "–∏—é–Ω—è": 6,
    "–ª–∏–ø–Ω—è": 7, "–∏—é–ª—è": 7,
    "—Å–µ—Ä–ø–Ω—è": 8, "–∞–≤–≥—É—Å—Ç–∞": 8,
    "–≤–µ—Ä–µ—Å–Ω—è": 9, "—Å–µ–Ω—Ç—è–±—Ä—è": 9,
    "–∂–æ–≤—Ç–Ω—è": 10, "–æ–∫—Ç—è–±—Ä—è": 10,
    "–ª–∏—Å—Ç–æ–ø–∞–¥–∞": 11, "–Ω–æ—è–±—Ä—è": 11,
    "–≥—Ä—É–¥–Ω—è": 12, "–¥–µ–∫–∞–±—Ä—è": 12,
}

def extract_date_from_text(text: str) -> str | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å—Ç–∞"""
    t = text.lower()

    # 1) dd.mm.yyyy / dd-mm-yyyy / dd/mm/yyyy
    m = re.search(r'(^|\D)(\d{1,2})[.\-/](\d{1,2})[.\-/](\d{4})(\D|$)', t)
    if m:
        d, mo, y = int(m.group(2)), int(m.group(3)), int(m.group(4))
        try:
            return date(y, mo, d).isoformat()
        except Exception:
            pass

    # 2) dd.mm (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π)
    m = re.search(r'(^|\D)(\d{1,2})[.\-/](\d{1,2})(\D|$)', t)
    if m:
        d, mo = int(m.group(2)), int(m.group(3))
        y = date.today().year
        try:
            return date(y, mo, d).isoformat()
        except Exception:
            pass

    # 3) "24 —Å—ñ—á–Ω—è 2026" / "24 —è–Ω–≤–∞—Ä—è 2026"
    m = re.search(r'(^|\D)(\d{1,2})\s+([–∞-—è—ñ—ó—î]+)\s+(\d{4})(\D|$)', t)
    if m:
        d = int(m.group(2))
        mon_name = m.group(3)
        y = int(m.group(4))
        mo = MONTHS_UA_RU.get(mon_name)
        if mo:
            try:
                return date(y, mo, d).isoformat()
            except Exception:
                pass

    # 4) "24 —Å—ñ—á–Ω—è" (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π)
    m = re.search(r'(^|\D)(\d{1,2})\s+([–∞-—è—ñ—ó—î]+)(\D|$)', t)
    if m:
        d = int(m.group(2))
        mon_name = m.group(3)
        mo = MONTHS_UA_RU.get(mon_name)
        if mo:
            today = date.today()
            y = today.year
            
            # –ï—Å–ª–∏ –¥–∞—Ç–∞ –≤ –ø—Ä–æ—à–ª–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞—à–ª–∏ "24 —è–Ω–≤–∞—Ä—è" –∞ —Å–µ–π—á–∞—Å –∫–æ–Ω–µ—Ü —è–Ω–≤–∞—Ä—è)
            # –∏ —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª—å—à–µ 20 –¥–Ω–µ–π - –∑–Ω–∞—á–∏—Ç —ç—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥
            try:
                parsed_date = date(y, mo, d)
                if parsed_date < today and (today - parsed_date).days > 20:
                    y += 1
                    parsed_date = date(y, mo, d)
                return parsed_date.isoformat()
            except Exception:
                pass

    return None


def date_from_message_ts(ts: int) -> str:
    if ts and ts > 1000000000:
        return datetime.fromtimestamp(ts, tz=timezone.utc).date().isoformat()
    return date.today().isoformat()


def main():
    page = fetch_with_retry(TG_URL)
    
    debug_mode = os.getenv("DEBUG_HTML", "0") == "1"
    if debug_mode:
        with open("debug_page.html", "w", encoding="utf-8") as f:
            f.write(page)
        print("Debug: Saved page HTML to debug_page.html")

    msgs = extract_messages(page)
    if not msgs:
        with open("error_page.html", "w", encoding="utf-8") as f:
            f.write(page)
        print("ERROR: Saved failing page to error_page.html for analysis")
        raise RuntimeError("No messages parsed from t.me/s page")

    print(f"Total messages parsed: {len(msgs)}")
    print(f"Checking last {min(LOOKBACK, len(msgs))} messages...")
    
    if msgs:
        latest_msg = msgs[-1]
        ts = latest_msg.get('ts', 0)
        if ts > 1000000000:
            latest_dt = datetime.fromtimestamp(ts, tz=timezone.utc)
            print(f"Latest message timestamp: {latest_dt} UTC (ts={ts})")
        else:
            print(f"Latest message timestamp: INVALID (ts={ts})")
        print(f"Latest message post ID: {latest_msg.get('post')}")
        print(f"Latest message preview: {latest_msg['text'][:150]}...")

    # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    today = date.today()
    tomorrow = today + timedelta(days=1)
    candidates = []
    
    print(f"\nüîç Analyzing posts for schedules...")
    
    for m in reversed(msgs[-LOOKBACK:]):
        if not has_group_lines(m["text"]):
            continue
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        post_date = extract_date_from_text(m["text"])
        post_preview = m["text"][:100].replace('\n', ' ')
        
        if not post_date:
            if m.get('ts', 0) > 1000000000:
                post_date = date_from_message_ts(m['ts'])
                print(f"  ‚ö†Ô∏è  No date in text, using timestamp: {post_date} | {post_preview}...")
            else:
                post_date = today.isoformat()
                print(f"  ‚ö†Ô∏è  No date found, using today: {post_date} | {post_preview}...")
        else:
            print(f"  ‚úÖ Found date in text: {post_date} | {post_preview}...")
        
        score = 0
        
        if has_keywords(m["text"]):
            score += 1000
        
        if m.get('ts', 0) > 1000000000:
            score += m['ts'] // 1000
        
        try:
            post_date_obj = date.fromisoformat(post_date)
            if post_date_obj == today:
                score += 100000
                print(f"    üìÖ Date is TODAY - high priority!")
            elif post_date_obj == tomorrow:
                score += 50000
                print(f"    üìÖ Date is TOMORROW - medium priority")
            elif post_date_obj > tomorrow:
                score += 10000
        except:
            pass
        
        score += len(m["text"]) // 10
        
        candidates.append({
            'msg': m,
            'score': score,
            'date': post_date
        })
    
    if not candidates:
        raise RuntimeError("No posts with schedules found")
    
    candidates.sort(key=lambda x: x['score'], reverse=True)
    
    print(f"\nFound {len(candidates)} candidates:")
    for i, c in enumerate(candidates[:5]):
        ts = c['msg'].get('ts', 0)
        if ts > 1000000000:
            msg_dt = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M')
        else:
            msg_dt = "INVALID_TS"
        print(f"  {i+1}. Score={c['score']}, Date={c['date']}, Time={msg_dt}, Post={c['msg'].get('post')}")
        print(f"     Preview: {c['msg']['text'][:80]}...")
    
    best = candidates[0]['msg']
    date_str = candidates[0]['date']

    print(f"\nüéØ Selected post ID: {best.get('post')}")
    ts = best.get('ts', 0)
    if ts > 1000000000:
        print(f"Post timestamp: {datetime.fromtimestamp(ts, tz=timezone.utc)}")
    else:
        print(f"Post timestamp: INVALID (ts={ts})")
    print(f"Post date: {date_str}")
    print(f"Post preview:\n{best['text'][:300]}...\n")

    groups = parse_groups(best["text"])
    print(f"Parsed {len(groups)} groups: {list(groups.keys())}")

    existing = load_existing()
    old_groups = existing.get("groups", {})
    old_date = existing.get("date")

    groups_changed = old_groups != groups
    date_changed = old_date != date_str
    
    if not groups_changed and not date_changed:
        print("‚úÖ Groups and date unchanged -> no update needed.")
        return
    
    if groups_changed:
        print(f"üìù Groups changed: {len(old_groups)} -> {len(groups)}")
    
    if date_changed:
        print(f"üìÖ Date changed: {old_date} -> {date_str}")

    save_schedule(groups, date_str)

    print(f"\n‚úÖ Schedule saved to {SCHEDULE_PATH}")
    print(f"Channel: {CHANNEL}")
    print(f"Post: {best.get('post')}")
    print(f"Date: {date_str}")
    print(f"Groups: {len(groups)}")

if __name__ == "__main__":
    main()

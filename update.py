import os
import re
import json
import html
import subprocess
import time
from datetime import datetime, date, timezone, timedelta
from random import randint
import requests

# ====== –ù–ê–°–¢–†–û–ô–ö–ò ======
CHANNEL = os.getenv("TG_CHANNEL", "dnepr_svet_voda").strip()
TG_URL = f"https://t.me/s/{CHANNEL}"
SCHEDULE_PATH = os.getenv("SCHEDULE_PATH", "schedule.json")
TIMEZONE_NAME = os.getenv("TIMEZONE", "Europe/Kyiv")

KEYWORDS = [k.strip().lower() for k in os.getenv(
    "TG_KEYWORDS",
    "–æ–Ω–æ–≤,–æ–Ω–æ–≤–∏–≤,–æ–Ω–æ–≤–∏–ª–∏—Å—å,–≥—Ä–∞—Ñ–∏–∫,–≥—Ä–∞—Ñ—ñ–∫–∏,–≥—Ä–∞—Ñ—ñ–∫,–¥—Ç–µ–∫,yasno,–≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è,–≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è —Å–≤—ñ—Ç–ª–∞,—á–µ—Ä–≥–∞,–≥—Ä—É–ø–∞"
).split(",") if k.strip()]

LOOKBACK = int(os.getenv("TG_LOOKBACK", "200"))  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 80 –¥–æ 200

# –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –∫–æ–º–º–∏—Ç–∏—Ç—å –¥–∞–∂–µ –ø—Ä–∏ —Ç–µ—Ö –∂–µ –≥—Ä—É–ø–ø–∞—Ö, –Ω–æ –Ω–æ–≤–∞—è –¥–∞—Ç–∞ ‚Äî 1
UPDATE_IF_DATE_CHANGED = os.getenv("UPDATE_IF_DATE_CHANGED", "0") == "1"

GITHUB_REPO = os.getenv("GITHUB_REPO", "")
GITHUB_PAT = os.getenv("GITHUB_PAT", "")
GIT_NAME = os.getenv("GIT_NAME", "Auto Updater")
GIT_EMAIL = os.getenv("GIT_EMAIL", "auto@local")


# ====== git helpers ======
def run(cmd: list[str]):
    subprocess.check_call(cmd)

def git_push_if_changed():
    try:
        status = subprocess.check_output(["git", "status", "--porcelain"], text=True).strip()
        if not status:
            print("No changes to commit.")
            return

        run(["git", "config", "user.name", GIT_NAME])
        run(["git", "config", "user.email", GIT_EMAIL])
        run(["git", "add", SCHEDULE_PATH])
        run(["git", "commit", "-m", f"update schedule {date.today()}"])

        # Pull –ø–µ—Ä–µ–¥ push —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
        try:
            run(["git", "pull", "--rebase"])
        except subprocess.CalledProcessError:
            print("Warning: git pull failed, trying to push anyway...")

        if GITHUB_REPO and GITHUB_PAT:
            repo_with_pat = re.sub(r"^https://", f"https://{GITHUB_PAT}@", GITHUB_REPO)
            run(["git", "push", repo_with_pat, "HEAD:main"])
        else:
            run(["git", "push"])
        
        print("‚úÖ Successfully pushed changes to repository")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Git operation failed: {e}")
        raise


# ====== schedule helpers ======
def load_existing():
    if not os.path.exists(SCHEDULE_PATH):
        return {}
    with open(SCHEDULE_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

def save_schedule(groups: dict, date_str: str):
    data = {"date": date_str, "timezone": TIMEZONE_NAME, "groups": groups}
    with open(SCHEDULE_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ====== –£–ª—É—á—à–µ–Ω–Ω—ã–π fetch —Å –æ–±—Ö–æ–¥–æ–º –∫—ç—à–∞ ======
def fetch_with_retry(url: str, retries: int = 3):
    """–ü—ã—Ç–∞–µ–º—Å—è –æ–±–æ–π—Ç–∏ –∫—ç—à —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ User-Agent –∏ timestamp"""
    
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    ]
    
    for i in range(retries):
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º timestamp —á—Ç–æ–±—ã –æ–±–æ–π—Ç–∏ –∫—ç—à
            cache_buster = f"?_={int(time.time() * 1000)}"
            headers = {
                'User-Agent': user_agents[i % len(user_agents)],
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'uk-UA,uk;q=0.9,en-US;q=0.8,en;q=0.7'
            }
            
            print(f"Fetching {url} (attempt {i+1}/{retries})...")
            r = requests.get(url + cache_buster, headers=headers, timeout=20)
            r.raise_for_status()
            print(f"Successfully fetched page ({len(r.text)} bytes)")
            return r.text
        except Exception as e:
            print(f"Attempt {i+1} failed: {e}")
            if i == retries - 1:
                raise
            time.sleep(randint(2, 5))


# ====== Telegram HTML parsing ======
def extract_messages(page_html: str):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Telegram
    """
    msgs = []
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤—Å–µ div —Å –∫–ª–∞—Å—Å–æ–º tgme_widget_message
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
    message_divs = re.findall(
        r'<div[^>]*class="[^"]*tgme_widget_message[^"]*"[^>]*>(.*?)</div>\s*</div>\s*</div>',
        page_html,
        re.S
    )
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
    if not message_divs:
        message_divs = re.findall(
            r'<div[^>]*data-post="[^"]+?"[^>]*>(.*?)</section>',
            page_html,
            re.S
        )
    
    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –ø–æ data-post –Ω–∞–ø—Ä—è–º—É—é
    if not message_divs:
        # –ò—â–µ–º –±–ª–æ–∫–∏ —Å data-post
        post_blocks = re.finditer(
            r'data-post="([^"]+)"[^>]*>.*?data-unixtime="(\d+)".*?<div[^>]*class="[^"]*tgme_widget_message_text[^"]*"[^>]*>(.*?)</div>',
            page_html,
            re.S
        )
        
        for match in post_blocks:
            post_id = match.group(1)
            ts = int(match.group(2))
            text_html = match.group(3)
            
            # –û—á–∏—Å—Ç–∫–∞ HTML
            text_html = text_html.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")
            text_plain = re.sub(r"<.*?>", "", text_html)
            text_plain = html.unescape(text_plain).strip()
            
            if text_plain:
                msgs.append({"ts": ts, "post": post_id, "text": text_plain})
        
        if msgs:
            msgs.sort(key=lambda x: x["ts"])
            return msgs
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥)
    for block in message_divs:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º timestamp
        m_ts = re.search(r'data-unixtime="(\d+)"', block)
        ts = int(m_ts.group(1)) if m_ts else 0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º post ID
        m_post = re.search(r'data-post="([^"]+)"', block)
        post_id = m_post.group(1) if m_post else ""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        m_text = re.search(r'<div[^>]*class="[^"]*tgme_widget_message_text[^"]*"[^>]*>(.*?)</div>', block, re.S)
        if not m_text:
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            m_text = re.search(r'class="js-message_text[^"]*"[^>]*>(.*?)</div>', block, re.S)
        
        if not m_text:
            continue
        
        text_html = m_text.group(1)
        text_html = text_html.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")
        text_plain = re.sub(r"<.*?>", "", text_html)
        text_plain = html.unescape(text_plain).strip()
        
        if text_plain:
            msgs.append({"ts": ts, "post": post_id, "text": text_plain})
    
    msgs.sort(key=lambda x: x["ts"])
    return msgs


def has_group_lines(text: str) -> bool:
    return bool(re.search(r'(^|\n)\s*\d+\.\d+\s*[-‚Äì‚Äî]\s*\d{2}:\d{2}\s*-\s*(\d{2}:\d{2}|24:00)', text))


def has_keywords(text: str) -> bool:
    low = text.lower()
    return any(k in low for k in KEYWORDS)


def parse_groups(text: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
    - 1.1 03:00 - 10:00 / 13:30 - 20:30
    - 1.1 - 08:00-12:00, 16:00-20:00
    - 1.1: 08:00-12:00; 16:00-20:00
    """
    groups = {}
    norm = text.replace("‚Äì", "-").replace("‚Äî", "-").replace("‚àí", "-")

    for line in norm.splitlines():
        line = line.strip()
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏ –º–∞—Ä–∫–µ—Ä—ã
        line = line.lstrip("‚Ä¢").lstrip("üî¥").lstrip("‚ùå").lstrip("-").strip()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: "1.1 03:00 - 10:00 / 13:30 - 20:30"
        m = re.match(r"^(\d+\.\d+)\s+(.+)$", line)
        if not m:
            continue

        group_id = m.group(1)
        rest = m.group(2).strip()
        
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è –∏–ª–∏ —Ç–∏—Ä–µ –≤ –Ω–∞—á–∞–ª–µ
        rest = re.sub(r"^[-:]\s*", "", rest)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø–æ /, ; –∏–ª–∏ –∑–∞–ø—è—Ç–æ–π
        parts = [p.strip() for p in re.split(r"[/;,]", rest) if p.strip()]
        
        intervals = []
        for part in parts:
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ —Ç–∏—Ä–µ
            part = re.sub(r"\s*-\s*", "-", part)
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            part = re.sub(r"\s+", " ", part).strip()
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–µ–º–µ–Ω–∏
            # –§–æ—Ä–º–∞—Ç: 03:00-10:00 –∏–ª–∏ 03:00 - 10:00
            time_matches = re.findall(r"\d{2}:\d{2}", part)
            
            if len(time_matches) >= 2:
                # –°–æ–∑–¥–∞—ë–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –∏–∑ –ø–∞—Ä –≤—Ä–µ–º—ë–Ω
                for i in range(0, len(time_matches), 2):
                    if i + 1 < len(time_matches):
                        interval = f"{time_matches[i]}-{time_matches[i+1]}"
                        intervals.append(interval)
            elif len(time_matches) == 1:
                # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –≤—Ä–µ–º—è, –≤–æ–∑–º–æ–∂–Ω–æ —Ñ–æ—Ä–º–∞—Ç "–¥–æ 24:00"
                if "24:00" in part or "00:00" in part:
                    interval = f"{time_matches[0]}-24:00"
                    intervals.append(interval)

        if intervals:
            groups[group_id] = intervals

    if not groups:
        raise RuntimeError("Parsed 0 groups from candidate post (format changed?)")
    
    return groups


# ====== Extract date from post text ======
MONTHS_UA_RU = {
    "—Å—ñ—á–Ω—è": 1, "—è–Ω–≤–∞—Ä—è": 1,
    "–ª—é—Ç–æ–≥–æ": 2, "—Ñ–µ–≤—Ä–∞–ª—è": 2,
    "–±–µ—Ä–µ–∑–Ω—è": 3, "–º–∞—Ä—Ç–∞": 3,
    "–∫–≤—ñ—Ç–Ω—è": 4, "–∞–ø—Ä–µ–ª—è": 4,
    "—Ç—Ä–∞–≤–Ω—è": 5, "–º–∞—è": 5,
    "—á–µ—Ä–≤–Ω—è": 6, "–∏—é–Ω—è": 6,
    "–ª–∏–ø–Ω—è": 7, "–∏—é–ª—è": 7,
    "—Å–µ—Ä–ø–Ω—è": 8, "–∞–≤–≥—É—Å—Ç–∞": 8,
    "–≤–µ—Ä–µ—Å–Ω—è": 9, "—Å–µ–Ω—Ç—è–±—Ä—è": 9,
    "–∂–æ–≤—Ç–Ω—è": 10, "–æ–∫—Ç—è–±—Ä—è": 10,
    "–ª–∏—Å—Ç–æ–ø–∞–¥–∞": 11, "–Ω–æ—è–±—Ä—è": 11,
    "–≥—Ä—É–¥–Ω—è": 12, "–¥–µ–∫–∞–±—Ä—è": 12,
}

def extract_date_from_text(text: str) -> str | None:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–∞—Ç—É –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ—Å—Ç–∞ –∏ –≤–µ—Ä–Ω—É—Ç—å YYYY-MM-DD.
    –ü–æ–¥–¥–µ—Ä–∂–∫–∞:
      - 24.01.2026 / 24/01/2026 / 24-01-2026
      - 24.01 (–≥–æ–¥ –±–µ—Ä—ë–º —Ç–µ–∫—É—â–∏–π)
      - 24 —Å—ñ—á–Ω—è 2026 / 24 —è–Ω–≤–∞—Ä—è 2026
      - 24 —Å—ñ—á–Ω—è (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π)
    """
    t = text.lower()

    # 1) dd.mm.yyyy / dd-mm-yyyy / dd/mm/yyyy
    m = re.search(r'(^|\D)(\d{1,2})[.\-/](\d{1,2})[.\-/](\d{4})(\D|$)', t)
    if m:
        d, mo, y = int(m.group(2)), int(m.group(3)), int(m.group(4))
        try:
            return date(y, mo, d).isoformat()
        except Exception:
            pass

    # 2) dd.mm (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π)
    m = re.search(r'(^|\D)(\d{1,2})[.\-/](\d{1,2})(\D|$)', t)
    if m:
        d, mo = int(m.group(2)), int(m.group(3))
        y = date.today().year
        try:
            return date(y, mo, d).isoformat()
        except Exception:
            pass

    # 3) "24 —Å—ñ—á–Ω—è 2026" / "24 —è–Ω–≤–∞—Ä—è 2026"
    m = re.search(r'(^|\D)(\d{1,2})\s+([–∞-—è—ñ—ó—î]+)\s+(\d{4})(\D|$)', t)
    if m:
        d = int(m.group(2))
        mon_name = m.group(3)
        y = int(m.group(4))
        mo = MONTHS_UA_RU.get(mon_name)
        if mo:
            try:
                return date(y, mo, d).isoformat()
            except Exception:
                pass

    # 4) "24 —Å—ñ—á–Ω—è" (–≥–æ–¥ —Ç–µ–∫—É—â–∏–π)
    m = re.search(r'(^|\D)(\d{1,2})\s+([–∞-—è—ñ—ó—î]+)(\D|$)', t)
    if m:
        d = int(m.group(2))
        mon_name = m.group(3)
        mo = MONTHS_UA_RU.get(mon_name)
        if mo:
            y = date.today().year
            try:
                return date(y, mo, d).isoformat()
            except Exception:
                pass

    return None


def date_from_message_ts(ts: int) -> str:
    if ts:
        # ts –≤ UTC, –Ω–æ –¥–ª—è –¥–∞—Ç—ã –Ω–∞–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –¥–Ω—è (Kyiv).
        # –ü—Ä–æ—Å—Ç–µ–π—à–∏–π —Å–ø–æ—Å–æ–± –±–µ–∑ pytz: –ø—Ä–∏–º–µ–Ω–∏–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–¥–≤–∏–≥ +2/+3 —Å–ª–æ–∂–Ω–æ.
        # –ü–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º UTC-–¥–∞—Ç—É –∫–∞–∫ fallback ‚Äî –æ–±—ã—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç.
        return datetime.fromtimestamp(ts, tz=timezone.utc).date().isoformat()
    return date.today().isoformat()


def main():
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π fetch
    page = fetch_with_retry(TG_URL)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    debug_mode = os.getenv("DEBUG_HTML", "0") == "1"
    if debug_mode:
        with open("debug_page.html", "w", encoding="utf-8") as f:
            f.write(page)
        print("Debug: Saved page HTML to debug_page.html")

    msgs = extract_messages(page)
    if not msgs:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –ø—Ä–∏ –æ—à–∏–±–∫–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        with open("error_page.html", "w", encoding="utf-8") as f:
            f.write(page)
        print("ERROR: Saved failing page to error_page.html for analysis")
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ —Å data-post
        data_posts = re.findall(r'data-post="([^"]+)"', page)
        print(f"Found {len(data_posts)} data-post attributes in HTML")
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ message_text
        text_divs = re.findall(r'class="[^"]*message_text[^"]*"', page)
        print(f"Found {len(text_divs)} message_text divs in HTML")
        
        raise RuntimeError("No messages parsed from t.me/s page (maybe blocked or HTML changed)")

    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    print(f"Total messages parsed: {len(msgs)}")
    print(f"Checking last {LOOKBACK} messages...")
    if msgs:
        latest_msg = msgs[-1]
        latest_dt = datetime.fromtimestamp(latest_msg['ts'], tz=timezone.utc)
        print(f"Latest message timestamp: {latest_dt} UTC")
        print(f"Latest message post ID: {latest_msg.get('post')}")
        print(f"Latest message preview: {latest_msg['text'][:150]}...")

    # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –∏—â–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π –≥—Ä–∞—Ñ–∏–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
    now = datetime.now(timezone.utc)
    one_day_ago = now - timedelta(days=1)
    
    candidates = []
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–æ—Å—Ç—ã
    for m in reversed(msgs[-LOOKBACK:]):
        msg_time = datetime.fromtimestamp(m['ts'], tz=timezone.utc)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤
        if msg_time < one_day_ago:
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥—Ä—É–ø–ø
        if not has_group_lines(m["text"]):
            continue
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –ø–æ—Å—Ç–∞
        post_date = extract_date_from_text(m["text"])
        if not post_date:
            post_date = date_from_message_ts(m.get("ts", 0))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
        score = 0
        
        # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if has_keywords(m["text"]):
            score += 100
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å–≤–µ–∂–µ—Å—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤–∞–∂–Ω–µ–µ)
        score += m['ts']
        
        # –ë–æ–Ω—É—Å –µ—Å–ª–∏ –¥–∞—Ç–∞ –≤ –ø–æ—Å—Ç–µ = —Å–µ–≥–æ–¥–Ω—è –∏–ª–∏ –∑–∞–≤—Ç—Ä–∞
        today = date.today()
        tomorrow = today + timedelta(days=1)
        try:
            post_date_obj = date.fromisoformat(post_date)
            if post_date_obj == today:
                score += 1000
            elif post_date_obj == tomorrow:
                score += 500
        except:
            pass
        
        candidates.append({
            'msg': m,
            'score': score,
            'date': post_date
        })
    
    if not candidates:
        print("WARNING: No candidates found in last 24 hours, falling back to old logic")
        # –°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –∫–∞–∫ fallback
        best = None
        for m in reversed(msgs[-LOOKBACK:]):
            if has_group_lines(m["text"]) and has_keywords(m["text"]):
                best = m
                break
        
        if best is None:
            for m in reversed(msgs[-LOOKBACK:]):
                if has_group_lines(m["text"]):
                    print("WARNING: no keyword match; using latest post that contains group lines")
                    best = m
                    break
        
        if best is None:
            raise RuntimeError("No suitable post found in last LOOKBACK messages")
        
        date_str = extract_date_from_text(best["text"])
        if not date_str:
            date_str = date_from_message_ts(best.get("ts", 0))
    else:
        # –í—ã–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º score
        candidates.sort(key=lambda x: x['score'], reverse=True)
        
        print(f"\nFound {len(candidates)} candidates:")
        for i, c in enumerate(candidates[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5
            msg_dt = datetime.fromtimestamp(c['msg']['ts'], tz=timezone.utc)
            print(f"  {i+1}. Score={c['score']}, Date={c['date']}, Time={msg_dt}, Post={c['msg'].get('post')}")
            print(f"     Preview: {c['msg']['text'][:80]}...")
        
        best = candidates[0]['msg']
        date_str = candidates[0]['date']

    print(f"\nüéØ Selected post ID: {best.get('post')}")
    print(f"Post timestamp: {datetime.fromtimestamp(best.get('ts', 0), tz=timezone.utc)}")
    print(f"Post date: {date_str}")
    print(f"Post preview:\n{best['text'][:300]}...\n")

    groups = parse_groups(best["text"])
    print(f"Parsed {len(groups)} groups: {list(groups.keys())}")

    existing = load_existing()
    old_groups = existing.get("groups", {})
    old_date = existing.get("date")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    groups_changed = old_groups != groups
    date_changed = old_date != date_str
    
    if not groups_changed and not date_changed:
        print("‚úÖ Groups and date unchanged -> no update needed.")
        return
    
    if groups_changed:
        print(f"üìù Groups changed: {len(old_groups)} -> {len(groups)}")
    
    if date_changed:
        print(f"üìÖ Date changed: {old_date} -> {date_str}")

    save_schedule(groups, date_str)
    
    # Git push —Ç–µ–ø–µ—Ä—å –¥–µ–ª–∞–µ—Ç workflow, –Ω–µ —Å–∫—Ä–∏–ø—Ç
    # git_push_if_changed()

    print(f"\n‚úÖ Updated from channel={CHANNEL}, post={best.get('post')}, ts={best.get('ts')}, date={date_str}")

if __name__ == "__main__":
    main()
